{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Dataset"
      ],
      "metadata": {
        "id": "s7dyfqTwqXLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -u \"./dataset.zip\" -d \"./dataset\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwhGewbtrNye",
        "outputId": "f2b59a73-24ae-4776-e6e0-470e28ce9014"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ./dataset.zip\n",
            "   creating: ./dataset/dataset/\n",
            "  inflating: ./dataset/__MACOSX/._dataset  \n",
            "  inflating: ./dataset/dataset/.DS_Store  \n",
            "  inflating: ./dataset/__MACOSX/dataset/._.DS_Store  \n",
            "   creating: ./dataset/dataset/train/\n",
            "  inflating: ./dataset/__MACOSX/dataset/._train  \n",
            "  inflating: ./dataset/dataset/val_set_coco.json  \n",
            "  inflating: ./dataset/__MACOSX/dataset/._val_set_coco.json  \n",
            "  inflating: ./dataset/dataset/training_set_coco.json  \n",
            "  inflating: ./dataset/__MACOSX/dataset/._training_set_coco.json  \n",
            "   creating: ./dataset/dataset/val/\n",
            "  inflating: ./dataset/__MACOSX/dataset/._val  \n",
            "  inflating: ./dataset/dataset/train/10.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._10.jpeg  \n",
            "  inflating: ./dataset/dataset/train/26.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._26.jpeg  \n",
            "  inflating: ./dataset/dataset/train/30.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._30.jpeg  \n",
            "  inflating: ./dataset/dataset/train/.DS_Store  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._.DS_Store  \n",
            "  inflating: ./dataset/dataset/train/27.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._27.jpeg  \n",
            "  inflating: ./dataset/dataset/train/1.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._1.jpeg  \n",
            "  inflating: ./dataset/dataset/train/11.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._11.jpeg  \n",
            "  inflating: ./dataset/dataset/train/20.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._20.jpeg  \n",
            "  inflating: ./dataset/dataset/train/6.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._6.jpeg  \n",
            "  inflating: ./dataset/dataset/train/16.jpg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._16.jpg  \n",
            "  inflating: ./dataset/dataset/train/7.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._7.jpeg  \n",
            "  inflating: ./dataset/dataset/train/17.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._17.jpeg  \n",
            "  inflating: ./dataset/dataset/train/21.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._21.jpeg  \n",
            "  inflating: ./dataset/dataset/train/8.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._8.jpeg  \n",
            "  inflating: ./dataset/dataset/train/22.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._22.jpeg  \n",
            "  inflating: ./dataset/dataset/train/18.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._18.jpeg  \n",
            "  inflating: ./dataset/dataset/train/4.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._4.jpeg  \n",
            "  inflating: ./dataset/dataset/train/14.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._14.jpeg  \n",
            "  inflating: ./dataset/dataset/train/15.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._15.jpeg  \n",
            "  inflating: ./dataset/dataset/train/5.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._5.jpeg  \n",
            "  inflating: ./dataset/dataset/train/32.jpg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._32.jpg  \n",
            "  inflating: ./dataset/dataset/train/19.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._19.jpeg  \n",
            "  inflating: ./dataset/dataset/train/23.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._23.jpeg  \n",
            "  inflating: ./dataset/dataset/train/9.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._9.jpeg  \n",
            "  inflating: ./dataset/dataset/train/31.jpg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._31.jpg  \n",
            "  inflating: ./dataset/dataset/train/2.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._2.jpeg  \n",
            "  inflating: ./dataset/dataset/train/28.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._28.jpeg  \n",
            "  inflating: ./dataset/dataset/train/12.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._12.jpeg  \n",
            "  inflating: ./dataset/dataset/train/24.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._24.jpeg  \n",
            "  inflating: ./dataset/dataset/train/25.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._25.jpeg  \n",
            "  inflating: ./dataset/dataset/train/13.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._13.jpeg  \n",
            "  inflating: ./dataset/dataset/train/29.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._29.jpeg  \n",
            "  inflating: ./dataset/dataset/train/3.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._3.jpeg  \n",
            "  inflating: ./dataset/dataset/val/47.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/val/._47.jpeg  \n",
            "  inflating: ./dataset/dataset/val/.DS_Store  \n",
            "  inflating: ./dataset/__MACOSX/dataset/val/._.DS_Store  \n",
            "  inflating: ./dataset/dataset/val/46.jpeg  \n",
            "  inflating: ./dataset/dataset/val/36.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/val/._36.jpeg  \n",
            "  inflating: ./dataset/dataset/val/41.jpeg  \n",
            "  inflating: ./dataset/dataset/val/40.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/val/._40.jpeg  \n",
            "  inflating: ./dataset/dataset/val/39.jpg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/val/._39.jpg  \n",
            "  inflating: ./dataset/dataset/val/38.jpg  \n",
            "  inflating: ./dataset/dataset/val/34.jpeg  \n",
            "  inflating: ./dataset/dataset/val/43.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/val/._43.jpeg  \n",
            "  inflating: ./dataset/dataset/val/37.jpg  \n",
            "  inflating: ./dataset/dataset/val/42.jpeg  \n",
            "  inflating: ./dataset/dataset/val/35.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/val/._35.jpeg  \n",
            "  inflating: ./dataset/dataset/val/48.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/val/._48.jpeg  \n",
            "  inflating: ./dataset/dataset/val/33.jpeg  \n",
            "  inflating: ./dataset/dataset/val/45.jpg  \n",
            "  inflating: ./dataset/dataset/val/44.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/val/._44.jpeg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us create a class for our dataset"
      ],
      "metadata": {
        "id": "cJBSjKEZtF68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.utils.data\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "from pycocotools.coco import COCO\n",
        "\n",
        "class myOwnDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, annotation, transforms=None):\n",
        "        self.root = root\n",
        "        self.transforms = transforms\n",
        "        self.coco = COCO(annotation)\n",
        "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Own coco file\n",
        "        coco = self.coco\n",
        "        # Image ID\n",
        "        img_id = self.ids[index]\n",
        "        # List: get annotation id from coco\n",
        "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
        "        # Dictionary: target coco_annotation file for an image\n",
        "        coco_annotation = coco.loadAnns(ann_ids)\n",
        "        # path for input image\n",
        "        path = coco.loadImgs(img_id)[0]['file_name']\n",
        "        # open the input image\n",
        "        img = Image.open(os.path.join(self.root, path))\n",
        "\n",
        "        # number of objects in the image\n",
        "        num_objs = len(coco_annotation)\n",
        "\n",
        "        # Bounding boxes for objects\n",
        "        # In coco format, bbox = [xmin, ymin, width, height]\n",
        "        # In pytorch, the input should be [xmin, ymin, xmax, ymax]\n",
        "        boxes = []\n",
        "        for i in range(num_objs):\n",
        "            xmin = coco_annotation[i]['bbox'][0]\n",
        "            ymin = coco_annotation[i]['bbox'][1]\n",
        "            xmax = xmin + coco_annotation[i]['bbox'][2]\n",
        "            ymax = ymin + coco_annotation[i]['bbox'][3]\n",
        "            boxes.append([xmin, ymin, xmax, ymax])\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        # Labels\n",
        "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
        "        # Tensorise img_id\n",
        "        img_id = torch.tensor([img_id])\n",
        "        # Size of bbox (Rectangular)\n",
        "        areas = []\n",
        "        for i in range(num_objs):\n",
        "            areas.append(coco_annotation[i]['area'])\n",
        "        areas = torch.as_tensor(areas, dtype=torch.float32)\n",
        "        # Iscrowd\n",
        "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
        "\n",
        "        # Annotation is in dictionary format\n",
        "        my_annotation = {}\n",
        "        my_annotation[\"boxes\"] = boxes\n",
        "        my_annotation[\"labels\"] = labels\n",
        "        #my_annotation[\"image_id\"] = img_id\n",
        "        my_annotation[\"image_id\"] = self.ids[index]\n",
        "        #my_annotation[\"image_id\"] = index\n",
        "        my_annotation[\"area\"] = areas\n",
        "        my_annotation[\"iscrowd\"] = iscrowd\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            img = self.transforms(img)\n",
        "\n",
        "        return img, my_annotation\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "# Since inputs for a PyTorch model must be in tensor format.\n",
        "def get_transform():\n",
        "    custom_transforms = []\n",
        "    custom_transforms.append(torchvision.transforms.ToTensor())\n",
        "    return torchvision.transforms.Compose(custom_transforms)"
      ],
      "metadata": {
        "id": "y0ywir93rYYh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will setup the DataLoaders (one for training set and one for validation set)"
      ],
      "metadata": {
        "id": "btYNRpH1tMAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# path to the data and coco file\n",
        "train_data_dir = 'dataset/dataset/train'\n",
        "train_coco = 'dataset/dataset/training_set_coco.json'\n",
        "\n",
        "val_data_dir = 'dataset/dataset/val'\n",
        "val_coco = 'dataset/dataset/val_set_coco.json'\n",
        "\n",
        "\n",
        "# create own Dataset for training and validation\n",
        "tr_dataset = myOwnDataset(root=train_data_dir,\n",
        "                          annotation=train_coco,\n",
        "                          transforms=get_transform()\n",
        "                          )\n",
        "\n",
        "val_dataset = myOwnDataset(root=val_data_dir,\n",
        "                          annotation=val_coco,\n",
        "                          transforms=get_transform()\n",
        "                          )\n",
        "\n",
        "\n",
        "# collate_fn needs for batch\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "# Batch size\n",
        "train_batch_size = 1\n",
        "val_batch_size = 1\n",
        "\n",
        "# own DataLoaders\n",
        "data_loader_train = torch.utils.data.DataLoader(tr_dataset,\n",
        "                                          batch_size=train_batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=4,\n",
        "                                          collate_fn=collate_fn)\n",
        "\n",
        "data_loader_val = torch.utils.data.DataLoader(val_dataset,\n",
        "                                          batch_size=val_batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=4,\n",
        "                                          collate_fn=collate_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1VpgJogtRZr",
        "outputId": "1bc01576-7a4a-46db-8ccf-35a3e2cb4c21"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the model"
      ],
      "metadata": {
        "id": "Fz0lgQpNvQjW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some dependencies"
      ],
      "metadata": {
        "id": "x5Y-gmmczyjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/engine.py\")\n",
        "os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/utils.py\")\n",
        "os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_utils.py\")\n",
        "os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_eval.py\")\n",
        "os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/transforms.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tY4L0_mz1Oy",
        "outputId": "f6fe1f14-073a-4b94-8142-63b5e7f42873"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models.detection.faster_rcnn import *\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from engine import train_one_epoch, evaluate\n",
        "\n",
        "def get_model_instance_segmentation(num_classes):\n",
        "    # load an instance segmentation model pre-trained pre-trained on COCO\n",
        "    #model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False)\n",
        "    #model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_320_fpn(pretrained=False,weights='DEFAULT')\n",
        "    model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_fpn(pretrained=False,weights='DEFAULT')\n",
        "    # get number of input features for the classifier\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    # replace the pre-trained head with a new one\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "    return model\n",
        "\n",
        "# select device (whether GPU or CPU)\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# 5 classes; 4 target classes and the background\n",
        "num_classes = 5\n",
        "num_epochs = 5\n",
        "model = get_model_instance_segmentation(num_classes)\n",
        "\n",
        "# move model to the right device\n",
        "model.to(device)\n",
        "\n",
        "# parameters\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
        "    optimizer,\n",
        "    step_size=3,\n",
        "    gamma=0.1\n",
        ")\n",
        "len_dataloader = len(data_loader_train)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # train for one epoch, printing every 10 iterations\n",
        "    train_one_epoch(model, optimizer, data_loader_train, device, epoch, print_freq=10)\n",
        "    # update the learning rate\n",
        "    lr_scheduler.step()\n",
        "    # evaluate on the test dataset\n",
        "    evaluate(model, data_loader_val, device=device)\n",
        "\n",
        "#for epoch in range(num_epochs):\n",
        "#    model.train()\n",
        "#    i = 0\n",
        "#    for imgs, annotations in data_loader_train:\n",
        "#        i += 1\n",
        "#        imgs = list(img.to(device) for img in imgs)\n",
        "#        annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n",
        "#        loss_dict = model(imgs, annotations)\n",
        "#        losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        " #       optimizer.zero_grad()\n",
        " #       losses.backward()\n",
        " #       optimizer.step()\n",
        "\n",
        " #       print(f'Iteration: {i}/{len_dataloader}, Loss: {losses}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hl12RGtvXiA",
        "outputId": "e8ac45ab-18aa-4583-e6ed-63aed1389329"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/fasterrcnn_mobilenet_v3_large_fpn-fb6a3cc7.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_mobilenet_v3_large_fpn-fb6a3cc7.pth\n",
            "100%|██████████| 74.2M/74.2M [00:00<00:00, 137MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0]  [ 0/32]  eta: 0:01:28  lr: 0.000166  loss: 1.9970 (1.9970)  loss_classifier: 1.2916 (1.2916)  loss_box_reg: 0.5986 (0.5986)  loss_objectness: 0.0060 (0.0060)  loss_rpn_box_reg: 0.1008 (0.1008)  time: 2.7787  data: 0.1225\n",
            "Epoch: [0]  [10/32]  eta: 0:01:01  lr: 0.001777  loss: 1.6193 (1.7042)  loss_classifier: 1.1674 (1.0017)  loss_box_reg: 0.5986 (0.5993)  loss_objectness: 0.0109 (0.0332)  loss_rpn_box_reg: 0.0433 (0.0699)  time: 2.7827  data: 0.0154\n",
            "Epoch: [0]  [20/32]  eta: 0:00:32  lr: 0.003389  loss: 1.4265 (1.4535)  loss_classifier: 0.4318 (0.7308)  loss_box_reg: 0.4801 (0.6061)  loss_objectness: 0.0095 (0.0433)  loss_rpn_box_reg: 0.0424 (0.0733)  time: 2.7357  data: 0.0048\n",
            "Epoch: [0]  [30/32]  eta: 0:00:05  lr: 0.005000  loss: 0.9056 (1.3137)  loss_classifier: 0.2807 (0.5837)  loss_box_reg: 0.4848 (0.5819)  loss_objectness: 0.0096 (0.0760)  loss_rpn_box_reg: 0.0426 (0.0721)  time: 2.8141  data: 0.0044\n",
            "Epoch: [0]  [31/32]  eta: 0:00:02  lr: 0.005000  loss: 0.9569 (1.3230)  loss_classifier: 0.3100 (0.5840)  loss_box_reg: 0.4848 (0.5734)  loss_objectness: 0.0096 (0.0929)  loss_rpn_box_reg: 0.0426 (0.0728)  time: 2.7866  data: 0.0042\n",
            "Epoch: [0] Total time: 0:01:30 (2.8145 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/16]  eta: 0:00:29  model_time: 1.6716 (1.6716)  evaluator_time: 0.0020 (0.0020)  time: 1.8241  data: 0.1503\n",
            "Test:  [15/16]  eta: 0:00:01  model_time: 1.1352 (1.2309)  evaluator_time: 0.0014 (0.0040)  time: 1.2484  data: 0.0124\n",
            "Test: Total time: 0:00:20 (1.2645 s / it)\n",
            "Averaged stats: model_time: 1.1352 (1.2309)  evaluator_time: 0.0014 (0.0040)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.331\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.610\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.265\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.278\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.404\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.191\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.463\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.530\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.416\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.621\n",
            "Epoch: [1]  [ 0/32]  eta: 0:02:35  lr: 0.005000  loss: 0.5652 (0.5652)  loss_classifier: 0.0786 (0.0786)  loss_box_reg: 0.0618 (0.0618)  loss_objectness: 0.0199 (0.0199)  loss_rpn_box_reg: 0.4049 (0.4049)  time: 4.8667  data: 0.2498\n",
            "Epoch: [1]  [10/32]  eta: 0:01:16  lr: 0.005000  loss: 0.5089 (0.6078)  loss_classifier: 0.1095 (0.1632)  loss_box_reg: 0.1464 (0.2242)  loss_objectness: 0.0617 (0.0993)  loss_rpn_box_reg: 0.1031 (0.1211)  time: 3.4548  data: 0.0254\n",
            "Epoch: [1]  [20/32]  eta: 0:00:39  lr: 0.005000  loss: 0.5726 (0.7484)  loss_classifier: 0.1391 (0.2314)  loss_box_reg: 0.2220 (0.2736)  loss_objectness: 0.0925 (0.1359)  loss_rpn_box_reg: 0.0598 (0.1075)  time: 3.2339  data: 0.0032\n",
            "Epoch: [1]  [30/32]  eta: 0:00:06  lr: 0.005000  loss: 0.7351 (0.7760)  loss_classifier: 0.1985 (0.2388)  loss_box_reg: 0.2920 (0.2967)  loss_objectness: 0.1037 (0.1282)  loss_rpn_box_reg: 0.0811 (0.1124)  time: 3.1732  data: 0.0033\n",
            "Epoch: [1]  [31/32]  eta: 0:00:03  lr: 0.005000  loss: 0.7351 (0.7672)  loss_classifier: 0.1985 (0.2327)  loss_box_reg: 0.2920 (0.2913)  loss_objectness: 0.1037 (0.1247)  loss_rpn_box_reg: 0.0943 (0.1184)  time: 3.1400  data: 0.0033\n",
            "Epoch: [1] Total time: 0:01:45 (3.2921 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/16]  eta: 0:00:30  model_time: 1.5417 (1.5417)  evaluator_time: 0.0018 (0.0018)  time: 1.8846  data: 0.3410\n",
            "Test:  [15/16]  eta: 0:00:01  model_time: 1.1702 (1.4662)  evaluator_time: 0.0020 (0.0041)  time: 1.4953  data: 0.0239\n",
            "Test: Total time: 0:00:24 (1.5054 s / it)\n",
            "Averaged stats: model_time: 1.1702 (1.4662)  evaluator_time: 0.0020 (0.0041)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.683\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.335\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.210\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.459\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.188\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.479\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.544\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.437\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.629\n",
            "Epoch: [2]  [ 0/32]  eta: 0:02:33  lr: 0.005000  loss: 0.3703 (0.3703)  loss_classifier: 0.1493 (0.1493)  loss_box_reg: 0.1147 (0.1147)  loss_objectness: 0.0610 (0.0610)  loss_rpn_box_reg: 0.0454 (0.0454)  time: 4.7868  data: 0.2095\n",
            "Epoch: [2]  [10/32]  eta: 0:01:15  lr: 0.005000  loss: 0.4163 (0.5125)  loss_classifier: 0.1360 (0.1344)  loss_box_reg: 0.1445 (0.2318)  loss_objectness: 0.0538 (0.0505)  loss_rpn_box_reg: 0.0574 (0.0959)  time: 3.4321  data: 0.0212\n",
            "Epoch: [2]  [20/32]  eta: 0:00:40  lr: 0.005000  loss: 0.4002 (0.4552)  loss_classifier: 0.0702 (0.1089)  loss_box_reg: 0.1376 (0.2031)  loss_objectness: 0.0378 (0.0463)  loss_rpn_box_reg: 0.0787 (0.0969)  time: 3.3291  data: 0.0033\n",
            "Epoch: [2]  [30/32]  eta: 0:00:06  lr: 0.005000  loss: 0.2770 (0.4951)  loss_classifier: 0.0465 (0.1333)  loss_box_reg: 0.1021 (0.2152)  loss_objectness: 0.0281 (0.0475)  loss_rpn_box_reg: 0.0827 (0.0990)  time: 3.3420  data: 0.0041\n",
            "Epoch: [2]  [31/32]  eta: 0:00:03  lr: 0.005000  loss: 0.3244 (0.5088)  loss_classifier: 0.0465 (0.1347)  loss_box_reg: 0.1021 (0.2267)  loss_objectness: 0.0341 (0.0496)  loss_rpn_box_reg: 0.0827 (0.0978)  time: 3.3420  data: 0.0041\n",
            "Epoch: [2] Total time: 0:01:48 (3.3829 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/16]  eta: 0:00:30  model_time: 1.7143 (1.7143)  evaluator_time: 0.0018 (0.0018)  time: 1.8760  data: 0.1595\n",
            "Test:  [15/16]  eta: 0:00:01  model_time: 1.1759 (1.2124)  evaluator_time: 0.0018 (0.0033)  time: 1.2301  data: 0.0131\n",
            "Test: Total time: 0:00:19 (1.2395 s / it)\n",
            "Averaged stats: model_time: 1.1759 (1.2124)  evaluator_time: 0.0018 (0.0033)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.454\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.850\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.464\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.337\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.556\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.193\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.521\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.586\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.654\n",
            "Epoch: [3]  [ 0/32]  eta: 0:01:38  lr: 0.000500  loss: 0.8813 (0.8813)  loss_classifier: 0.3197 (0.3197)  loss_box_reg: 0.3869 (0.3869)  loss_objectness: 0.0192 (0.0192)  loss_rpn_box_reg: 0.1554 (0.1554)  time: 3.0845  data: 0.1909\n",
            "Epoch: [3]  [10/32]  eta: 0:01:11  lr: 0.000500  loss: 0.3371 (0.4229)  loss_classifier: 0.0628 (0.1348)  loss_box_reg: 0.1017 (0.1860)  loss_objectness: 0.0168 (0.0204)  loss_rpn_box_reg: 0.0356 (0.0817)  time: 3.2676  data: 0.0223\n",
            "Epoch: [3]  [20/32]  eta: 0:00:38  lr: 0.000500  loss: 0.2151 (0.3651)  loss_classifier: 0.0376 (0.1108)  loss_box_reg: 0.0884 (0.1597)  loss_objectness: 0.0142 (0.0251)  loss_rpn_box_reg: 0.0356 (0.0695)  time: 3.2510  data: 0.0049\n",
            "Epoch: [3]  [30/32]  eta: 0:00:06  lr: 0.000500  loss: 0.2311 (0.3670)  loss_classifier: 0.0557 (0.1105)  loss_box_reg: 0.0723 (0.1586)  loss_objectness: 0.0134 (0.0318)  loss_rpn_box_reg: 0.0531 (0.0661)  time: 3.3262  data: 0.0039\n",
            "Epoch: [3]  [31/32]  eta: 0:00:03  lr: 0.000500  loss: 0.2151 (0.3596)  loss_classifier: 0.0479 (0.1079)  loss_box_reg: 0.0714 (0.1554)  loss_objectness: 0.0125 (0.0311)  loss_rpn_box_reg: 0.0531 (0.0652)  time: 3.3313  data: 0.0039\n",
            "Epoch: [3] Total time: 0:01:45 (3.3094 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/16]  eta: 0:00:36  model_time: 2.0016 (2.0016)  evaluator_time: 0.0093 (0.0093)  time: 2.2738  data: 0.2627\n",
            "Test:  [15/16]  eta: 0:00:01  model_time: 1.0772 (1.1986)  evaluator_time: 0.0014 (0.0029)  time: 1.2221  data: 0.0193\n",
            "Test: Total time: 0:00:19 (1.2316 s / it)\n",
            "Averaged stats: model_time: 1.0772 (1.1986)  evaluator_time: 0.0014 (0.0029)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.527\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.811\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.679\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.410\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.641\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.233\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.628\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.660\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.568\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.733\n",
            "Epoch: [4]  [ 0/32]  eta: 0:01:57  lr: 0.000500  loss: 0.1235 (0.1235)  loss_classifier: 0.0285 (0.0285)  loss_box_reg: 0.0604 (0.0604)  loss_objectness: 0.0061 (0.0061)  loss_rpn_box_reg: 0.0284 (0.0284)  time: 3.6630  data: 0.1879\n",
            "Epoch: [4]  [10/32]  eta: 0:01:11  lr: 0.000500  loss: 0.2180 (0.3853)  loss_classifier: 0.0760 (0.1329)  loss_box_reg: 0.0956 (0.1784)  loss_objectness: 0.0143 (0.0286)  loss_rpn_box_reg: 0.0436 (0.0455)  time: 3.2507  data: 0.0198\n",
            "Epoch: [4]  [20/32]  eta: 0:00:39  lr: 0.000500  loss: 0.1796 (0.2900)  loss_classifier: 0.0568 (0.0928)  loss_box_reg: 0.0658 (0.1353)  loss_objectness: 0.0102 (0.0215)  loss_rpn_box_reg: 0.0414 (0.0404)  time: 3.2548  data: 0.0034\n",
            "Epoch: [4]  [30/32]  eta: 0:00:06  lr: 0.000500  loss: 0.1648 (0.2596)  loss_classifier: 0.0303 (0.0782)  loss_box_reg: 0.0591 (0.1184)  loss_objectness: 0.0088 (0.0174)  loss_rpn_box_reg: 0.0392 (0.0457)  time: 3.3042  data: 0.0037\n",
            "Epoch: [4]  [31/32]  eta: 0:00:03  lr: 0.000500  loss: 0.1648 (0.2641)  loss_classifier: 0.0303 (0.0813)  loss_box_reg: 0.0591 (0.1204)  loss_objectness: 0.0084 (0.0171)  loss_rpn_box_reg: 0.0375 (0.0454)  time: 3.3010  data: 0.0037\n",
            "Epoch: [4] Total time: 0:01:45 (3.2928 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/16]  eta: 0:00:21  model_time: 1.1599 (1.1599)  evaluator_time: 0.0018 (0.0018)  time: 1.3267  data: 0.1648\n",
            "Test:  [15/16]  eta: 0:00:01  model_time: 1.0674 (1.0677)  evaluator_time: 0.0014 (0.0021)  time: 1.0848  data: 0.0139\n",
            "Test: Total time: 0:00:17 (1.0943 s / it)\n",
            "Averaged stats: model_time: 1.0674 (1.0677)  evaluator_time: 0.0014 (0.0021)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.531\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.821\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.648\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.420\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.642\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.230\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.619\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.644\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.532\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.733\n"
          ]
        }
      ]
    }
  ]
}