{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Dataset"
      ],
      "metadata": {
        "id": "s7dyfqTwqXLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -u \"./dataset.zip\" -d \"./dataset\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwhGewbtrNye",
        "outputId": "1c1da854-584b-48eb-ee07-12293b81c370"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ./dataset.zip\n",
            "   creating: ./dataset/dataset/\n",
            "  inflating: ./dataset/__MACOSX/._dataset  \n",
            "  inflating: ./dataset/dataset/.DS_Store  \n",
            "  inflating: ./dataset/__MACOSX/dataset/._.DS_Store  \n",
            "   creating: ./dataset/dataset/train/\n",
            "  inflating: ./dataset/__MACOSX/dataset/._train  \n",
            "  inflating: ./dataset/dataset/val_set_coco.json  \n",
            "  inflating: ./dataset/__MACOSX/dataset/._val_set_coco.json  \n",
            "  inflating: ./dataset/dataset/training_set_coco.json  \n",
            "  inflating: ./dataset/__MACOSX/dataset/._training_set_coco.json  \n",
            "   creating: ./dataset/dataset/val/\n",
            "  inflating: ./dataset/__MACOSX/dataset/._val  \n",
            "  inflating: ./dataset/dataset/train/10.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._10.jpeg  \n",
            "  inflating: ./dataset/dataset/train/26.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._26.jpeg  \n",
            "  inflating: ./dataset/dataset/train/30.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._30.jpeg  \n",
            "  inflating: ./dataset/dataset/train/.DS_Store  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._.DS_Store  \n",
            "  inflating: ./dataset/dataset/train/27.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._27.jpeg  \n",
            "  inflating: ./dataset/dataset/train/1.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._1.jpeg  \n",
            "  inflating: ./dataset/dataset/train/11.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._11.jpeg  \n",
            "  inflating: ./dataset/dataset/train/20.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._20.jpeg  \n",
            "  inflating: ./dataset/dataset/train/6.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._6.jpeg  \n",
            "  inflating: ./dataset/dataset/train/16.jpg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._16.jpg  \n",
            "  inflating: ./dataset/dataset/train/7.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._7.jpeg  \n",
            "  inflating: ./dataset/dataset/train/17.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._17.jpeg  \n",
            "  inflating: ./dataset/dataset/train/21.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._21.jpeg  \n",
            "  inflating: ./dataset/dataset/train/8.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._8.jpeg  \n",
            "  inflating: ./dataset/dataset/train/22.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._22.jpeg  \n",
            "  inflating: ./dataset/dataset/train/18.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._18.jpeg  \n",
            "  inflating: ./dataset/dataset/train/4.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._4.jpeg  \n",
            "  inflating: ./dataset/dataset/train/14.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._14.jpeg  \n",
            "  inflating: ./dataset/dataset/train/15.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._15.jpeg  \n",
            "  inflating: ./dataset/dataset/train/5.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._5.jpeg  \n",
            "  inflating: ./dataset/dataset/train/32.jpg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._32.jpg  \n",
            "  inflating: ./dataset/dataset/train/19.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._19.jpeg  \n",
            "  inflating: ./dataset/dataset/train/23.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._23.jpeg  \n",
            "  inflating: ./dataset/dataset/train/9.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._9.jpeg  \n",
            "  inflating: ./dataset/dataset/train/31.jpg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._31.jpg  \n",
            "  inflating: ./dataset/dataset/train/2.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._2.jpeg  \n",
            "  inflating: ./dataset/dataset/train/28.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._28.jpeg  \n",
            "  inflating: ./dataset/dataset/train/12.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._12.jpeg  \n",
            "  inflating: ./dataset/dataset/train/24.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._24.jpeg  \n",
            "  inflating: ./dataset/dataset/train/25.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._25.jpeg  \n",
            "  inflating: ./dataset/dataset/train/13.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._13.jpeg  \n",
            "  inflating: ./dataset/dataset/train/29.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._29.jpeg  \n",
            "  inflating: ./dataset/dataset/train/3.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/train/._3.jpeg  \n",
            "  inflating: ./dataset/dataset/val/47.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/val/._47.jpeg  \n",
            "  inflating: ./dataset/dataset/val/.DS_Store  \n",
            "  inflating: ./dataset/__MACOSX/dataset/val/._.DS_Store  \n",
            "  inflating: ./dataset/dataset/val/46.jpeg  \n",
            "  inflating: ./dataset/dataset/val/36.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/val/._36.jpeg  \n",
            "  inflating: ./dataset/dataset/val/41.jpeg  \n",
            "  inflating: ./dataset/dataset/val/40.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/val/._40.jpeg  \n",
            "  inflating: ./dataset/dataset/val/39.jpg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/val/._39.jpg  \n",
            "  inflating: ./dataset/dataset/val/38.jpg  \n",
            "  inflating: ./dataset/dataset/val/34.jpeg  \n",
            "  inflating: ./dataset/dataset/val/43.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/val/._43.jpeg  \n",
            "  inflating: ./dataset/dataset/val/37.jpg  \n",
            "  inflating: ./dataset/dataset/val/42.jpeg  \n",
            "  inflating: ./dataset/dataset/val/35.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/val/._35.jpeg  \n",
            "  inflating: ./dataset/dataset/val/48.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/val/._48.jpeg  \n",
            "  inflating: ./dataset/dataset/val/33.jpeg  \n",
            "  inflating: ./dataset/dataset/val/45.jpg  \n",
            "  inflating: ./dataset/dataset/val/44.jpeg  \n",
            "  inflating: ./dataset/__MACOSX/dataset/val/._44.jpeg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us create a class for our dataset"
      ],
      "metadata": {
        "id": "cJBSjKEZtF68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.utils.data\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "from pycocotools.coco import COCO\n",
        "\n",
        "class myOwnDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, annotation, transforms=None):\n",
        "        self.root = root\n",
        "        self.transforms = transforms\n",
        "        self.coco = COCO(annotation)\n",
        "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Own coco file\n",
        "        coco = self.coco\n",
        "        # Image ID\n",
        "        img_id = self.ids[index]\n",
        "        # List: get annotation id from coco\n",
        "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
        "        # Dictionary: target coco_annotation file for an image\n",
        "        coco_annotation = coco.loadAnns(ann_ids)\n",
        "        # path for input image\n",
        "        path = coco.loadImgs(img_id)[0]['file_name']\n",
        "        # open the input image\n",
        "        img = Image.open(os.path.join(self.root, path))\n",
        "\n",
        "        # number of objects in the image\n",
        "        num_objs = len(coco_annotation)\n",
        "\n",
        "        # Bounding boxes for objects\n",
        "        # In coco format, bbox = [xmin, ymin, width, height]\n",
        "        # In pytorch, the input should be [xmin, ymin, xmax, ymax]\n",
        "        boxes = []\n",
        "        for i in range(num_objs):\n",
        "            xmin = coco_annotation[i]['bbox'][0]\n",
        "            ymin = coco_annotation[i]['bbox'][1]\n",
        "            xmax = xmin + coco_annotation[i]['bbox'][2]\n",
        "            ymax = ymin + coco_annotation[i]['bbox'][3]\n",
        "            boxes.append([xmin, ymin, xmax, ymax])\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        # Labels\n",
        "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
        "        # Tensorise img_id\n",
        "        img_id = torch.tensor([img_id])\n",
        "        # Size of bbox (Rectangular)\n",
        "        areas = []\n",
        "        for i in range(num_objs):\n",
        "            areas.append(coco_annotation[i]['area'])\n",
        "        areas = torch.as_tensor(areas, dtype=torch.float32)\n",
        "        # Iscrowd\n",
        "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
        "\n",
        "        # Annotation is in dictionary format\n",
        "        my_annotation = {}\n",
        "        my_annotation[\"boxes\"] = boxes\n",
        "        my_annotation[\"labels\"] = labels\n",
        "        #my_annotation[\"image_id\"] = img_id\n",
        "        my_annotation[\"image_id\"] = self.ids[index]\n",
        "        #my_annotation[\"image_id\"] = index\n",
        "        my_annotation[\"area\"] = areas\n",
        "        my_annotation[\"iscrowd\"] = iscrowd\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            img = self.transforms(img)\n",
        "\n",
        "        return img, my_annotation\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "# Since inputs for a PyTorch model must be in tensor format.\n",
        "def get_transform():\n",
        "    custom_transforms = []\n",
        "    custom_transforms.append(torchvision.transforms.ToTensor())\n",
        "    return torchvision.transforms.Compose(custom_transforms)"
      ],
      "metadata": {
        "id": "y0ywir93rYYh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will setup the DataLoaders (one for training set and one for validation set)"
      ],
      "metadata": {
        "id": "btYNRpH1tMAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# path to the data and coco file\n",
        "train_data_dir = 'dataset/dataset/train'\n",
        "train_coco = 'dataset/dataset/training_set_coco.json'\n",
        "\n",
        "val_data_dir = 'dataset/dataset/val'\n",
        "val_coco = 'dataset/dataset/val_set_coco.json'\n",
        "\n",
        "\n",
        "# create own Dataset for training and validation\n",
        "tr_dataset = myOwnDataset(root=train_data_dir,\n",
        "                          annotation=train_coco,\n",
        "                          transforms=get_transform()\n",
        "                          )\n",
        "\n",
        "val_dataset = myOwnDataset(root=val_data_dir,\n",
        "                          annotation=val_coco,\n",
        "                          transforms=get_transform()\n",
        "                          )\n",
        "\n",
        "\n",
        "# collate_fn needs for batch\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "# Batch size\n",
        "train_batch_size = 1\n",
        "val_batch_size = 1\n",
        "\n",
        "# own DataLoaders\n",
        "data_loader_train = torch.utils.data.DataLoader(tr_dataset,\n",
        "                                          batch_size=train_batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=4,\n",
        "                                          collate_fn=collate_fn)\n",
        "\n",
        "data_loader_val = torch.utils.data.DataLoader(val_dataset,\n",
        "                                          batch_size=val_batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=4,\n",
        "                                          collate_fn=collate_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1VpgJogtRZr",
        "outputId": "5d660f8d-9d2f-4742-e408-422502e14b96"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the model"
      ],
      "metadata": {
        "id": "Fz0lgQpNvQjW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some dependencies"
      ],
      "metadata": {
        "id": "x5Y-gmmczyjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/engine.py\")\n",
        "os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/utils.py\")\n",
        "os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_utils.py\")\n",
        "os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_eval.py\")\n",
        "os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/transforms.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tY4L0_mz1Oy",
        "outputId": "650e3a4c-8237-4e8c-f42d-5936c43011c2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models.detection.faster_rcnn import *\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from engine import train_one_epoch, evaluate\n",
        "\n",
        "def get_model_instance_segmentation(num_classes):\n",
        "    # load an instance segmentation model pre-trained pre-trained on COCO\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights='DEFAULT')\n",
        "    #model = torchvision.models.detection.fasterrcnn_resnet50_fpn_v2(weights='DEFAULT')\n",
        "    #model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_320_fpn(weights='DEFAULT')\n",
        "    #model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_fpn(weights='DEFAULT')\n",
        "    # get number of input features for the classifier\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    # replace the pre-trained head with a new one\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "    return model\n",
        "\n",
        "# select device (whether GPU or CPU)\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# 5 classes; 4 target classes and the background\n",
        "num_classes = 5\n",
        "num_epochs = 5\n",
        "model = get_model_instance_segmentation(num_classes)\n",
        "\n",
        "# move model to the right device\n",
        "model.to(device)\n",
        "\n",
        "# parameters\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
        "    optimizer,\n",
        "    step_size=3,\n",
        "    gamma=0.1\n",
        ")\n",
        "len_dataloader = len(data_loader_train)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # train for one epoch, printing every 10 iterations\n",
        "    train_one_epoch(model, optimizer, data_loader_train, device, epoch, print_freq=10)\n",
        "    # update the learning rate\n",
        "    lr_scheduler.step()\n",
        "    # evaluate on the test dataset\n",
        "    evaluate(model, data_loader_val, device=device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hl12RGtvXiA",
        "outputId": "c094f47f-2ebd-45c4-8e3b-8bf89aa87855"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_v2_coco-dd69338a.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_v2_coco-dd69338a.pth\n",
            "100%|██████████| 167M/167M [00:01<00:00, 143MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0]  [ 0/32]  eta: 0:21:28  lr: 0.000166  loss: 2.0186 (2.0186)  loss_classifier: 1.8821 (1.8821)  loss_box_reg: 0.0863 (0.0863)  loss_objectness: 0.0213 (0.0213)  loss_rpn_box_reg: 0.0290 (0.0290)  time: 40.2762  data: 0.2009\n",
            "Epoch: [0]  [10/32]  eta: 0:12:08  lr: 0.001777  loss: 1.3880 (1.3838)  loss_classifier: 1.2762 (1.1658)  loss_box_reg: 0.1084 (0.1868)  loss_objectness: 0.0153 (0.0165)  loss_rpn_box_reg: 0.0103 (0.0147)  time: 33.1052  data: 0.0197\n",
            "Epoch: [0]  [20/32]  eta: 0:06:33  lr: 0.003389  loss: 0.3742 (0.9404)  loss_classifier: 0.1945 (0.7329)  loss_box_reg: 0.0993 (0.1611)  loss_objectness: 0.0135 (0.0292)  loss_rpn_box_reg: 0.0114 (0.0171)  time: 32.4034  data: 0.0025\n",
            "Epoch: [0]  [30/32]  eta: 0:01:04  lr: 0.005000  loss: 0.2286 (0.8388)  loss_classifier: 0.1039 (0.6077)  loss_box_reg: 0.0963 (0.1796)  loss_objectness: 0.0161 (0.0340)  loss_rpn_box_reg: 0.0190 (0.0174)  time: 31.6545  data: 0.0034\n",
            "Epoch: [0]  [31/32]  eta: 0:00:32  lr: 0.005000  loss: 0.2286 (0.8176)  loss_classifier: 0.1039 (0.5905)  loss_box_reg: 0.0963 (0.1770)  loss_objectness: 0.0161 (0.0331)  loss_rpn_box_reg: 0.0114 (0.0170)  time: 31.4974  data: 0.0034\n",
            "Epoch: [0] Total time: 0:17:07 (32.1111 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/16]  eta: 0:03:40  model_time: 13.2868 (13.2868)  evaluator_time: 0.0149 (0.0149)  time: 13.7568  data: 0.4549\n",
            "Test:  [15/16]  eta: 0:00:13  model_time: 13.2378 (13.0646)  evaluator_time: 0.0038 (0.0056)  time: 13.1018  data: 0.0304\n",
            "Test: Total time: 0:03:29 (13.1172 s / it)\n",
            "Averaged stats: model_time: 13.2378 (13.0646)  evaluator_time: 0.0038 (0.0056)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.261\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.628\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.131\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.179\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.345\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.163\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.402\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.502\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.458\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.537\n",
            "Epoch: [1]  [ 0/32]  eta: 0:17:50  lr: 0.005000  loss: 0.2955 (0.2955)  loss_classifier: 0.1120 (0.1120)  loss_box_reg: 0.1621 (0.1621)  loss_objectness: 0.0183 (0.0183)  loss_rpn_box_reg: 0.0031 (0.0031)  time: 33.4436  data: 0.2499\n",
            "Epoch: [1]  [10/32]  eta: 0:10:56  lr: 0.005000  loss: 0.2841 (0.2743)  loss_classifier: 0.0904 (0.0940)  loss_box_reg: 0.1599 (0.1489)  loss_objectness: 0.0253 (0.0277)  loss_rpn_box_reg: 0.0025 (0.0038)  time: 29.8412  data: 0.0260\n",
            "Epoch: [1]  [20/32]  eta: 0:06:16  lr: 0.005000  loss: 0.1587 (0.2352)  loss_classifier: 0.0846 (0.0836)  loss_box_reg: 0.0615 (0.1242)  loss_objectness: 0.0172 (0.0198)  loss_rpn_box_reg: 0.0046 (0.0077)  time: 31.3096  data: 0.0042\n",
            "Epoch: [1]  [30/32]  eta: 0:01:04  lr: 0.005000  loss: 0.1129 (0.2563)  loss_classifier: 0.0491 (0.0962)  loss_box_reg: 0.0480 (0.1356)  loss_objectness: 0.0045 (0.0152)  loss_rpn_box_reg: 0.0088 (0.0092)  time: 33.4072  data: 0.0045\n",
            "Epoch: [1]  [31/32]  eta: 0:00:32  lr: 0.005000  loss: 0.1042 (0.2512)  loss_classifier: 0.0418 (0.0944)  loss_box_reg: 0.0480 (0.1324)  loss_objectness: 0.0041 (0.0148)  loss_rpn_box_reg: 0.0094 (0.0096)  time: 33.3368  data: 0.0045\n",
            "Epoch: [1] Total time: 0:17:10 (32.2046 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/16]  eta: 0:03:50  model_time: 13.8953 (13.8953)  evaluator_time: 0.0064 (0.0064)  time: 14.4087  data: 0.5067\n",
            "Test:  [15/16]  eta: 0:00:13  model_time: 12.9694 (12.9909)  evaluator_time: 0.0024 (0.0036)  time: 13.0294  data: 0.0336\n",
            "Test: Total time: 0:03:29 (13.0649 s / it)\n",
            "Averaged stats: model_time: 12.9694 (12.9909)  evaluator_time: 0.0024 (0.0036)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.443\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.765\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.400\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.338\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.541\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.200\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.516\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.612\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.495\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.704\n",
            "Epoch: [2]  [ 0/32]  eta: 0:18:02  lr: 0.005000  loss: 0.1027 (0.1027)  loss_classifier: 0.0322 (0.0322)  loss_box_reg: 0.0438 (0.0438)  loss_objectness: 0.0177 (0.0177)  loss_rpn_box_reg: 0.0090 (0.0090)  time: 33.8129  data: 0.4015\n",
            "Epoch: [2]  [10/32]  eta: 0:11:55  lr: 0.005000  loss: 0.0961 (0.1251)  loss_classifier: 0.0311 (0.0397)  loss_box_reg: 0.0576 (0.0758)  loss_objectness: 0.0017 (0.0037)  loss_rpn_box_reg: 0.0065 (0.0058)  time: 32.5281  data: 0.0410\n",
            "Epoch: [2]  [20/32]  eta: 0:06:30  lr: 0.005000  loss: 0.0757 (0.1036)  loss_classifier: 0.0233 (0.0323)  loss_box_reg: 0.0424 (0.0627)  loss_objectness: 0.0017 (0.0037)  loss_rpn_box_reg: 0.0041 (0.0050)  time: 32.4641  data: 0.0046\n",
            "Epoch: [2]  [30/32]  eta: 0:01:04  lr: 0.005000  loss: 0.0658 (0.1251)  loss_classifier: 0.0187 (0.0405)  loss_box_reg: 0.0327 (0.0739)  loss_objectness: 0.0033 (0.0049)  loss_rpn_box_reg: 0.0041 (0.0059)  time: 31.9028  data: 0.0041\n",
            "Epoch: [2]  [31/32]  eta: 0:00:32  lr: 0.005000  loss: 0.0553 (0.1227)  loss_classifier: 0.0183 (0.0398)  loss_box_reg: 0.0323 (0.0723)  loss_objectness: 0.0031 (0.0048)  loss_rpn_box_reg: 0.0054 (0.0059)  time: 31.7844  data: 0.0040\n",
            "Epoch: [2] Total time: 0:17:10 (32.2154 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/16]  eta: 0:03:41  model_time: 13.3396 (13.3396)  evaluator_time: 0.0027 (0.0027)  time: 13.8273  data: 0.4848\n",
            "Test:  [15/16]  eta: 0:00:13  model_time: 13.3692 (13.3735)  evaluator_time: 0.0018 (0.0029)  time: 13.4104  data: 0.0328\n",
            "Test: Total time: 0:03:35 (13.4444 s / it)\n",
            "Averaged stats: model_time: 13.3692 (13.3735)  evaluator_time: 0.0018 (0.0029)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.501\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.764\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.593\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.341\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.633\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.253\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.556\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.665\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.547\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.758\n",
            "Epoch: [3]  [ 0/32]  eta: 0:17:23  lr: 0.000500  loss: 0.0873 (0.0873)  loss_classifier: 0.0382 (0.0382)  loss_box_reg: 0.0448 (0.0448)  loss_objectness: 0.0015 (0.0015)  loss_rpn_box_reg: 0.0029 (0.0029)  time: 32.6149  data: 0.3371\n",
            "Epoch: [3]  [10/32]  eta: 0:11:52  lr: 0.000500  loss: 0.0663 (0.0950)  loss_classifier: 0.0235 (0.0335)  loss_box_reg: 0.0303 (0.0561)  loss_objectness: 0.0015 (0.0019)  loss_rpn_box_reg: 0.0033 (0.0035)  time: 32.4036  data: 0.0343\n",
            "Epoch: [3]  [20/32]  eta: 0:06:24  lr: 0.000500  loss: 0.0480 (0.0823)  loss_classifier: 0.0179 (0.0294)  loss_box_reg: 0.0219 (0.0465)  loss_objectness: 0.0014 (0.0022)  loss_rpn_box_reg: 0.0041 (0.0043)  time: 32.0210  data: 0.0046\n",
            "Epoch: [3]  [30/32]  eta: 0:01:04  lr: 0.000500  loss: 0.0480 (0.0801)  loss_classifier: 0.0186 (0.0277)  loss_box_reg: 0.0219 (0.0467)  loss_objectness: 0.0009 (0.0019)  loss_rpn_box_reg: 0.0031 (0.0038)  time: 32.0280  data: 0.0045\n",
            "Epoch: [3]  [31/32]  eta: 0:00:32  lr: 0.000500  loss: 0.0409 (0.0786)  loss_classifier: 0.0170 (0.0271)  loss_box_reg: 0.0219 (0.0457)  loss_objectness: 0.0009 (0.0019)  loss_rpn_box_reg: 0.0031 (0.0038)  time: 32.1159  data: 0.0045\n",
            "Epoch: [3] Total time: 0:17:10 (32.2123 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/16]  eta: 0:03:37  model_time: 13.2345 (13.2345)  evaluator_time: 0.0031 (0.0031)  time: 13.5629  data: 0.3251\n",
            "Test:  [15/16]  eta: 0:00:12  model_time: 12.7758 (12.8090)  evaluator_time: 0.0013 (0.0023)  time: 12.8357  data: 0.0233\n",
            "Test: Total time: 0:03:25 (12.8601 s / it)\n",
            "Averaged stats: model_time: 12.7758 (12.8090)  evaluator_time: 0.0013 (0.0023)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.531\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.796\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.571\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.377\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.665\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.251\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.549\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.688\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.589\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.767\n",
            "Epoch: [4]  [ 0/32]  eta: 0:17:16  lr: 0.000500  loss: 0.0880 (0.0880)  loss_classifier: 0.0281 (0.0281)  loss_box_reg: 0.0367 (0.0367)  loss_objectness: 0.0198 (0.0198)  loss_rpn_box_reg: 0.0034 (0.0034)  time: 32.3871  data: 0.3772\n",
            "Epoch: [4]  [10/32]  eta: 0:11:22  lr: 0.000500  loss: 0.0472 (0.0873)  loss_classifier: 0.0187 (0.0299)  loss_box_reg: 0.0273 (0.0513)  loss_objectness: 0.0018 (0.0035)  loss_rpn_box_reg: 0.0030 (0.0025)  time: 31.0178  data: 0.0381\n",
            "Epoch: [4]  [20/32]  eta: 0:06:23  lr: 0.000500  loss: 0.0389 (0.0737)  loss_classifier: 0.0166 (0.0253)  loss_box_reg: 0.0215 (0.0426)  loss_objectness: 0.0010 (0.0032)  loss_rpn_box_reg: 0.0029 (0.0026)  time: 31.9659  data: 0.0043\n",
            "Epoch: [4]  [30/32]  eta: 0:01:04  lr: 0.000500  loss: 0.0365 (0.0710)  loss_classifier: 0.0125 (0.0245)  loss_box_reg: 0.0196 (0.0400)  loss_objectness: 0.0013 (0.0034)  loss_rpn_box_reg: 0.0029 (0.0031)  time: 32.6797  data: 0.0046\n",
            "Epoch: [4]  [31/32]  eta: 0:00:32  lr: 0.000500  loss: 0.0365 (0.0700)  loss_classifier: 0.0123 (0.0241)  loss_box_reg: 0.0167 (0.0393)  loss_objectness: 0.0014 (0.0034)  loss_rpn_box_reg: 0.0029 (0.0033)  time: 32.9709  data: 0.0047\n",
            "Epoch: [4] Total time: 0:17:05 (32.0509 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/16]  eta: 0:03:40  model_time: 13.4150 (13.4150)  evaluator_time: 0.0121 (0.0121)  time: 13.7740  data: 0.3467\n",
            "Test:  [15/16]  eta: 0:00:12  model_time: 12.8684 (12.8744)  evaluator_time: 0.0021 (0.0030)  time: 12.9040  data: 0.0259\n",
            "Test: Total time: 0:03:26 (12.9278 s / it)\n",
            "Averaged stats: model_time: 12.8684 (12.8744)  evaluator_time: 0.0021 (0.0030)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.514\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.788\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.561\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.657\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.244\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.556\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.658\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.526\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.762\n"
          ]
        }
      ]
    }
  ]
}